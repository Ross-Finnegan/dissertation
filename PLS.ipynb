{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#PLS imports\n",
    "from sys import stdout\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from scipy.signal import savgol_filter\n",
    "\n",
    "from sklearn.cross_decomposition import PLSRegression\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import numpy as np; print('numpy Version:', np.__version__)\n",
    "import pandas as pd; print('pandas Version:', pd.__version__)\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import StrMethodFormatter;\n",
    "import xgboost as xgb; print('XGBoost Version:', xgb.__version__)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_cleaned = pd.read_csv('SQL_extracted datasets/Formatted_data/FINALlanghill_mir_extractready_revised_7pm_mir_aligned_20210711.csv', sep=',')\n",
    "print(data_cleaned.shape) #Shape is 417657 rows and 18 columns\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### External Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data_cleaned.iloc[:, 14:1074]\n",
    "y = data_cleaned['weeklyave_FI']\n",
    "X2 = savgol_filter(X, 17, polyorder=2, deriv=2)\n",
    "X1 = savgol_filter(X, 17, polyorder=2, deriv=1)\n",
    "#Alternative split method which will randomly split the data\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "test_size = 0.1\n",
    "\n",
    "\n",
    "X_test, X_train, y_test, y_train =train_test_split(X1,y, train_size=0.1, random_state = 11)\n",
    "#_train, X_valid, y_train, y_valid = train_test_split(X_rem,y_rem, train_size=0.8)\n",
    "# check dimensions\n",
    "print('X_train: ', X_train.shape,  'y_train: ', y_train.shape)\n",
    "#print('X_validation', X_valid.shape, 'y_validation: ', y_valid.shape)\n",
    "print('X_test', X_test.shape, 'y_test: ', y_test.shape)\n",
    "\n",
    "\n",
    "# check the proportions\n",
    "total = X_train.shape[0]  + X_test.shape[0]\n",
    "print('X_train proportion:', X_train.shape[0] / total)\n",
    "#print('X_validation proportion:', X_valid.shape[0] / total)\n",
    "print('X_test proportion:', X_test.shape[0] / total)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PLS Prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = y_train\n",
    "X = X_train\n",
    "y.shape\n",
    "X.shape\n",
    "wl = np.arange(900, 5140, 4)\n",
    "\n",
    "print(len(wl))\n",
    "1060\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(wl, np.mean(X, axis = 0),   label = \"Mean value\", alpha = 1)\n",
    "ax.plot(wl, np.percentile(X, 99, axis = 0),  label = \"99th percentile\", alpha = .35)\n",
    "ax.plot(wl, np.percentile(X, 1, axis = 0), label = \"1st percentile\",  alpha = .35)\n",
    "#ax.plot(y_test, intercept + slope * y_test, label=line)\n",
    "\n",
    "plt.title('Untreated Spectrum')\n",
    "ax.set_xlabel('Wavenumber (cm$^{-1}$)')\n",
    "ax.set_ylabel('Absorbance')\n",
    "ax.legend(facecolor='white')\n",
    "plt.savefig('output3.png', dpi=250)\n",
    "plt.show()\n",
    "#fig.tight_layout()\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(wl, np.mean(X1, axis = 0), label = \"Mean value\",  alpha = 1)\n",
    "ax.plot(wl, np.percentile(X1, 99, axis = 0), label = \"99th percentile\", alpha = .35)\n",
    "\n",
    "ax.plot(wl, np.percentile(X1, 1, axis = 0), label = \"1st percentile\",  alpha = .35)\n",
    "\n",
    "#ax.plot(y_test, intercept + slope * y_test, label=line)\n",
    "\n",
    "plt.title('First Derivative Spectrum')\n",
    "ax.set_xlabel('Wavenumber (cm$^{-1}$)')\n",
    "ax.set_ylabel('Absorbance')\n",
    "ax.legend(facecolor='white')\n",
    "fig.tight_layout()\n",
    "plt.savefig('output6.png', dpi=250)\n",
    "\n",
    "plt.show()\n",
    "# Plot the data absorption at each datapoint - need to clarify the range & unit of wavelengths \n",
    "\n",
    "\n",
    "with plt.style.context('ggplot'):\n",
    "    plt.plot(wl, X.T)\n",
    "    plt.xlabel(\"Datapoint - some wavelength value\")\n",
    "    plt.ylabel(\"Absorbance\")\n",
    "https://www.kaggle.com/phamvanvung/partial-least-squares-regression-in-python\n",
    "#X2 = savgol_filter(X, 17, polyorder=2, deriv=2)\n",
    "X1 = savgol_filter(X, 17, polyorder=2, deriv=1)\n",
    "\n",
    "X1.shape\n",
    "plt.figure(figsize=(8, 4.5))\n",
    "with plt.style.context('ggplot'):\n",
    "    plt.plot(wl, X1.T)\n",
    "    plt.xlabel(\"Wavelengths (nm)\")\n",
    "    plt.ylabel(\"D1 Absorbance\")\n",
    "    plt.show()\n",
    "plt.figure(figsize=(8, 4.5))\n",
    "with plt.style.context('ggplot'):\n",
    "    plt.plot(wl, X2.T)\n",
    "    plt.xlabel(\"Wavelengths (nm)\")\n",
    "    plt.ylabel(\"D2 Absorbance\")\n",
    "    plt.show()\n",
    "def optimise_pls_cv(X1, y, n_comp, plot_components = True):\n",
    "    # Define PLS object\n",
    "    pls = PLSRegression(n_components=n_comp)\n",
    "\n",
    "    # Cross-validation\n",
    "    y_cv = cross_val_predict(pls, X1, y, cv=10)\n",
    "\n",
    "    # Calculate scores\n",
    "    r2 = r2_score(y, y_cv)\n",
    "    mse = mean_squared_error(y, y_cv)\n",
    "    rpd = y.std()/np.sqrt(mse)\n",
    "    \n",
    "    return (y_cv, r2, mse, rpd)\n",
    "%%time\n",
    "\n",
    "r2s = []\n",
    "mses = []\n",
    "rpds = []\n",
    "xticks = np.arange(1, 21)\n",
    "for n_comp in xticks:\n",
    "    y_cv, r2, mse, rpd = optimise_pls_cv(X, y, n_comp)\n",
    "    r2s.append(r2)\n",
    "    mses.append(mse)\n",
    "    rpds.append(rpd)\n",
    "CPU times: user 3h 40min 32s, sys: 3h 28min 54s, total: 7h 9min 27s\n",
    "Wall time: 16min 4s\n",
    "\n",
    " # Calculate and print the position of minimum in MSE      \n",
    "    msemin = np.argmin(mses)      \n",
    "    print(\"Suggested number of components: \", msemin+1)      \n",
    "    stdout.write(\"\\n\")\n",
    "Suggested number of components:  20\n",
    "import matplotlib.ticker as mticker\n",
    "# Plot the mses\n",
    "def plot_metrics(vals, ylabel, objective):\n",
    "    #with plt.style.context('ggplot'):\n",
    "    plt.plot(range(1, 21), np.array(vals), '-v')\n",
    "    if objective=='min':\n",
    "        idx = np.argmin(vals)\n",
    "    else:\n",
    "        idx = np.argmax(vals)\n",
    "    plt.plot(xticks[idx], np.array(vals)[idx], '*', ms=10, color = \"red\")\n",
    "\n",
    "    plt.ticklabel_format(style='plain', axis='x', useOffset=False)\n",
    "    #plt.plot(range(1, 20), logger.acc)\n",
    "    plt.gca().xaxis.set_major_locator(mticker.MultipleLocator(1))\n",
    "    plt.xlabel('Number of PLS components')\n",
    "    #plt.xticks(np.arange(1, 21,1.0))\n",
    "    #plt.xticks(range(1,20))\n",
    "    plt.ylabel(ylabel)\n",
    "    plt.title('Incremental value of each PLS component')\n",
    "\n",
    "    plt.show()\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(wl, np.mean(X1, axis = 0), label = \"Mean value\",  alpha = 1)\n",
    "ax.plot(wl, np.percentile(X1, 99, axis = 0), label = \"99th percentile\", alpha = .35)\n",
    "\n",
    "\n",
    "ax.plot(wl, np.percentile(X1, 1, axis = 0), label = \"1st percentile\",  alpha = .35)\n",
    "\n",
    "#ax.plot(y_test, intercept + slope * y_test, label=line)\n",
    "\n",
    "plt.title('First Derivative Spectrum')\n",
    "ax.set_xlabel('Wavenumber (cm$^{-1}$)')\n",
    "ax.set_ylabel('Absorbance')\n",
    "ax.legend(facecolor='white')\n",
    "\n",
    "\n",
    "fig.tight_layout()\n",
    "plt.savefig('output6.png', dpi=250)\n",
    "\n",
    "plt.show()\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2)\n",
    "fig.suptitle('Incremental value of each PLS component')\n",
    "objective = 'min'\n",
    "ylabel = 'RMSE'\n",
    "vals = np.sqrt(mses)\n",
    "\n",
    "ax1.plot(range(1, 21), np.array(vals), '-v')\n",
    "if objective=='min':\n",
    "    idx = np.argmin(vals)\n",
    "else:\n",
    "    idx = np.argmax(vals)\n",
    "ax1.plot(xticks[idx], np.array(vals)[idx], '*', ms=10, color = \"red\")\n",
    "\n",
    "ax1.ticklabel_format(style='plain', axis='x', useOffset=False)\n",
    "#plt.plot(range(1, 20), logger.acc)\n",
    "#plt.gca().xaxis.set_major_locator(mticker.MultipleLocator(1))\n",
    "ax1.set_xlabel('Number of PLS components')\n",
    "#plt.xticks(np.arange(1, 21,1.0))\n",
    "#plt.xticks(range(1,20))\n",
    "ax1.set_ylabel(ylabel)\n",
    "\n",
    "\n",
    "objective = 'max'\n",
    "ylabel = 'R$^{2}$'\n",
    "vals =r2s\n",
    "ax2.plot(range(1, 21), np.array(vals), '-v')\n",
    "if objective=='min':\n",
    "    idx = np.argmin(vals)\n",
    "else:\n",
    "    idx = np.argmax(vals)\n",
    "ax2.plot(xticks[idx], np.array(vals)[idx], '*', ms=10, color = \"red\")\n",
    "\n",
    "ax2.ticklabel_format(style='plain', axis='x', useOffset=False)\n",
    "#plt.plot(range(1, 20), logger.acc)\n",
    "#ax2.gca().xaxis.set_major_locator(mticker.MultipleLocator(1))\n",
    "ax2.set_xlabel('Number of PLS components')\n",
    "#plt.xticks(np.arange(1, 21,1.0))\n",
    "\n",
    "#plt.xticks(range(1,20))\n",
    "ax2.set_ylabel(ylabel)\n",
    "#fig.tight_layout()\n",
    "fig.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
    "\n",
    "\n",
    "plt.savefig('outputPLS.png', dpi=250)\n",
    "\n",
    "\n",
    "plot_metrics(np.sqrt(mses), 'RMSE', 'min')\n",
    "plot_metrics(r2s, 'R$^{2}$', 'max')\n",
    "x\n",
    "[0, 5, 9, 10, 15]\n",
    "# Define PLS object with optimal number of components      \n",
    "pls_opt = PLSRegression(n_components=msemin+1)        \n",
    "# Fit to the entire dataset   \n",
    "pls_opt.fit(X, y)     \n",
    "y_c = pls_opt.predict(X) \n",
    "\n",
    "np.std(y)\n",
    "%%time \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross-Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_cv = cross_val_predict(pls_opt, X, y, cv=10)       \n",
    "# Calculate scores for calibration and cross-validation      \n",
    "score_c = r2_score(y, y_c)      \n",
    "score_cv = r2_score(y, y_cv)        \n",
    "# Calculate mean squared error for calibration and cross validation      \n",
    "mse_c = mean_squared_error(y, y_c)  \n",
    "rmse_c = np.sqrt(mse_c)\n",
    "mse_cv = mean_squared_error(y, y_cv)   \n",
    "rmse_cv = np.sqrt(mse_cv)\n",
    "print('R2 calib: %5.3f'  % score_c)      \n",
    "print('R2 CV: %5.3f'  % score_cv)   \n",
    "print('R calib: %5.3f'  % np.sqrt(score_c)      )\n",
    "print('R CV: %5.3f'  % np.sqrt(score_cv)  )\n",
    "print('RMSE calib: %5.3f' % rmse_c)      \n",
    "print('RMSE CV: %5.3f' % rmse_cv)        \n",
    "\n",
    "# Plot regression and figures of merit      \n",
    "rangey = max(y) - min(y)      \n",
    "rangex = max(y_c) - min(y_c)        \n",
    "# Fit a line to the CV vs response      \n",
    "z = np.polyfit(y, y_c, 1)     \n",
    "with plt.style.context(('ggplot')):      \n",
    "    fig, ax = plt.subplots(figsize=(9, 5))   \n",
    "    ax.scatter(y_c, y, c='red', edgecolors='k')        \n",
    "    #Plot the best fit line        \n",
    "    ax.plot(np.polyval(z,y), y, c='blue', linewidth=1)     \n",
    "    #Plot the ideal 1:1 line          \n",
    "    ax.plot(y, y, color='green', linewidth=1)          \n",
    "    plt.title('$R^{2}$ (CV): '+str(score_cv))          \n",
    "    plt.xlabel('Predicted $^{\\circ}$Feed Intake')\n",
    "    plt.ylabel('Measured $^{\\circ}$Feed Intake')\n",
    "    plt.show() \n",
    "\n",
    "#Get std of RMSE\n",
    "ysq = np.sqrt(y)\n",
    "y_csq = np.sqrt(y_c[:,0])\n",
    "e = (ysq-y_csq)\n",
    "sd = np.std(e)\n",
    "\n",
    "print(\"Std of RMSE calib: \", sd)\n",
    "\n",
    "y_cvsq = np.sqrt(y_cv[:,0])\n",
    "e = (ysq-y_cvsq)\n",
    "sd = np.std(e)\n",
    "\n",
    "print(\"Std of RMSE CV: \", sd)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correlations & Measures of Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Corr: %0.4f, R2: %0.4f, RMSE: %0.4f, RPD: %0.4f' %(corr,r2, rmse, rpd))\n",
    "preds = pls_opt.predict(X_test) \n",
    "preds = preds[:,0]\n",
    "from scipy.stats import pearsonr\n",
    "# calculate Pearson's correlation\n",
    "corr, p = pearsonr(y_test, preds)\n",
    "print('Pearsons correlation: %.3f' % corr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "# calculate coeff of determination\n",
    "r2 = r2_score(y_test, preds)\n",
    "print('Coeff of determination: %.3f' % r2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "rmse = np.sqrt(mean_squared_error(y_test, preds))\n",
    "print('RMSE of prediction: %.3f' % rmse)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.8 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
